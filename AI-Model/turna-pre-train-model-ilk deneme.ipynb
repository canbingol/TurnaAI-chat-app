{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10197612,"sourceType":"datasetVersion","datasetId":6301084}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport tiktoken\nfrom torch.utils.data import Dataset, DataLoader\ntokenizer = tiktoken.get_encoding(\"gpt2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:44.931568Z","iopub.execute_input":"2025-03-19T12:49:44.931871Z","iopub.status.idle":"2025-03-19T12:49:49.464377Z","shell.execute_reply.started":"2025-03-19T12:49:44.931847Z","shell.execute_reply":"2025-03-19T12:49:49.463414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ModelConfig = {\n \"vocab_size\": 50257,  # Kelime dağarcığı boyutu\n \"context_length\": 256,  # Bağlam uzunluğu\n \"emb_dim\": 384,  # Gömülü (embedding) boyutu\n \"n_heads\": 12,  # Dikkat başlıklarının (attention heads) sayısı\n \"n_layers\": 12,  # Katman sayısı\n \"drop_rate\": 0.1,  # Dropout oranı\n \"qkv_bias\": False  # Sorgu-Anahtar-Değer (Query-Key-Value) bias'ı\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:49.465606Z","iopub.execute_input":"2025-03-19T12:49:49.465960Z","iopub.status.idle":"2025-03-19T12:49:49.469737Z","shell.execute_reply.started":"2025-03-19T12:49:49.465939Z","shell.execute_reply":"2025-03-19T12:49:49.468921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n\n    def __init__(self, emb_dim):\n        super().__init__()\n        self.eps = 1e-5  # Küçük bir sabit, sayısal kararlılık sağlamak için eklenir (0'a bölme hatalarını önler)\n        self.scale = nn.Parameter(torch.ones(emb_dim))  # Öğrenilebilir bir parametre: her katman için ölçekleme (scaling)\n        self.shift = nn.Parameter(torch.zeros(emb_dim))  # Öğrenilebilir bir parametre: her katman için kaydırma (shifting)\n\n    def forward(self, x):\n        # Giriş tensörünün son boyutunun ortalamasını hesapla (x'in her bir örneği için)\n        mean = x.mean(dim=-1, keepdim=True)\n\n        # Giriş tensörünün son boyutunun varyansını hesapla (x'in her bir örneği için)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n\n        # Normalizasyon işlemi: (x - mean) / sqrt(var + eps)\n        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n\n        # Sonuçları ölçekleme (scale) ve kaydırma (shift) parametreleriyle düzenle\n        return self.scale * norm_x + self.shift","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:49.471275Z","iopub.execute_input":"2025-03-19T12:49:49.471514Z","iopub.status.idle":"2025-03-19T12:49:49.490205Z","shell.execute_reply.started":"2025-03-19T12:49:49.471486Z","shell.execute_reply":"2025-03-19T12:49:49.489339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GELU(nn.Module):\n     def __init__(self):\n         super().__init__()\n     def forward(self, x):\n         return 0.5 * x * (1 + torch.tanh(\n         torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n         (x + 0.044715 * torch.pow(x, 3))\n         ))\n\nclass MLP(nn.Module):\n\n    def __init__(self, config:ModelConfig):\n        super().__init__()\n        self.emb_dim = config[\"emb_dim\"]\n        self.vocab_size = config[\"vocab_size\"]\n        self.context_len = config[\"context_length\"]\n        \n        self.layers = nn.Sequential(\n            nn.Linear(self.emb_dim, 4 * self.emb_dim),\n            GELU(),\n            nn.Linear(self.emb_dim * 4, self.emb_dim)\n        )\n\n    def forward(self,x):\n        return self.layers(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:49.491426Z","iopub.execute_input":"2025-03-19T12:49:49.491631Z","iopub.status.idle":"2025-03-19T12:49:49.500857Z","shell.execute_reply.started":"2025-03-19T12:49:49.491614Z","shell.execute_reply":"2025-03-19T12:49:49.500231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    # Yapıcı fonksiyon: Modelin başlangıç parametrelerini tanımlar.\n    def __init__(self, config):\n        super().__init__()\n        # Modelin iç parametreleri\n        self.emb_dim = config[\"emb_dim\"]  # Gömme (embedding) boyutu\n        self.qkv_bias = config[\"qkv_bias\"]  # Sorgu, anahtar ve değer için bias kullanılıp kullanılmayacağı\n        self.n_heads = config[\"n_heads\"]  # Başlık sayısı (multi-head attention)\n        self.context_length = config[\"context_length\"]  # Bağlam uzunluğu (örneğin, dil modeli için cümledeki kelime sayısı)\n        \n        # Her bir başlık için gömme boyutunu hesapla\n        self.head_dim = self.emb_dim // self.n_heads\n        # emb_dim'in n_heads'e bölünebilir olup olmadığını kontrol et\n        assert (self.emb_dim % self.n_heads == 0), \\\n             \"emb_dim must be divisible by num_heads\"\n    \n        # Sorgu (Q), anahtar (K) ve değer (V) için lineer dönüşümler\n        self.Wq = nn.Linear(self.emb_dim, self.emb_dim, bias=self.qkv_bias)\n        self.Wk = nn.Linear(self.emb_dim, self.emb_dim, bias=self.qkv_bias)\n        self.Wv = nn.Linear(self.emb_dim, self.emb_dim, bias=self.qkv_bias)\n        # Sonuç projeksiyonu: tüm başlıkların birleşiminden sonra son çıkışı hesaplayacak\n        self.out_proj = nn.Linear(self.emb_dim, self.emb_dim)\n        \n        # Mask oluşturuluyor: modelin sadece geçerli token'ları dikkate almasını sağlıyor\n        # Bu mask, geleceği görmesini engellemek için kullanılır (Özellikle dil modelleri için)\n        self.register_buffer(\n         \"mask\",\n        torch.triu(torch.ones(self.context_length, self.context_length),\n         diagonal=1\n                    ))\n        \n    def forward(self, x):\n        # Giriş verisi şekli: (batch_size, seq_len, emb_dim)\n        batch_size, seq_len, emb_dim = x.shape\n\n        # Sorgu, anahtar ve değer hesaplamaları: her biri için lineer projeksiyon\n        q = self.Wq(x)  # Sorgular (Query)\n        k = self.Wk(x)  # Anahtarlar (Key)\n        v = self.Wv(x)  # Değerler (Value)\n\n        # Başlıkları ayırmak için her birini yeniden şekillendiriyoruz\n        k = k.view(batch_size, seq_len, self.n_heads, self.head_dim)\n        v = v.view(batch_size, seq_len, self.n_heads, self.head_dim)\n        q = q.view(batch_size, seq_len, self.n_heads, self.head_dim)\n        \n        # Diziyi yeniden şekillendiriyoruz (k, q, v sırasıyla): (b, seq_len, n_heads, head_dim) -> (b, n_heads, seq_len, head_dim)\n        k = k.transpose(1, 2)\n        q = q.transpose(1, 2)\n        v = v.transpose(1, 2)\n        \n        # Dikkat skorlarını hesapla: Sorgu ve Anahtarların çarpımı\n        attn_scores = q @ k.transpose(2, 3)  # (b, n_heads, seq_len, seq_len)\n\n        # Mask uygulaması: modelin sadece geçerli token'ları kullanmasına izin verir\n        mask_bool = self.mask.bool()[:seq_len, :seq_len]  # Mask'ın uygun kısmını al\n        attn_scores.masked_fill_(mask_bool, -torch.inf)  # Geleceği görmesini engeller (sonsuz küçük bir değere ayarlama)\n\n        # Softmax uygulaması: Dikkat skorlarını normalleştir\n        attn_weights = torch.softmax(\n                attn_scores / k.shape[-1]**0.5, dim=-1\n                                        )  # Skorları normalize et, d_k (head_dim) ile ölçeklendir\n        \n        # Dikkat ağırlıkları ile değerleri çarp\n        context_vec = (attn_weights @ v).transpose(1, 2)  # (b, n_heads, seq_len, head_dim) -> (b, seq_len, n_heads, head_dim)\n        \n        # Başlıkları birleştir (d_out = n_heads * head_dim)\n        context_vec = context_vec.contiguous().view(\n             batch_size, seq_len, self.emb_dim\n                                                    )\n        \n        # Son projeksiyonu uygula: Başlıkları birleştirdikten sonra çıkışı hesapla\n        context_vec = self.out_proj(context_vec)  # Sonuçları projekte et\n\n        return context_vec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:49.501662Z","iopub.execute_input":"2025-03-19T12:49:49.501868Z","iopub.status.idle":"2025-03-19T12:49:49.515650Z","shell.execute_reply.started":"2025-03-19T12:49:49.501850Z","shell.execute_reply":"2025-03-19T12:49:49.514874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    # Yapıcı fonksiyon: Transformer bloğunu oluşturur\n    def __init__(self, config):\n        super().__init__()\n        # MultiHeadAttention modülünü başlatıyoruz\n        self.att = MultiHeadAttention(config)\n        # Feedforward (MLP) modülünü başlatıyoruz\n        self.ff = MLP(config)\n        # Layer normalization katmanlarını başlatıyoruz\n        self.norm1 = LayerNorm(config[\"emb_dim\"])  # İlk layer norm (attention öncesi)\n        self.norm2 = LayerNorm(config[\"emb_dim\"])  # İkinci layer norm (feedforward öncesi)\n        \n    def forward(self, x):\n        # Giriş verisinin kısa yolunu kaydediyoruz (residual connection)\n        shortcut = x\n        \n        # İlk normalization işlemi: Layer norm uygulandıktan sonra self-attention\n        x = self.norm1(x)  # İlk normalizasyon\n        x = self.att(x)  # Multi-head attention uygulaması\n        \n        # Residual connection: dikkat (self-attention) çıktısı kısa yol ile toplanır\n        x = x + shortcut  # Kısa yol bağlantısı ekleniyor\n        \n        # Yeni bir kısa yol oluşturuyoruz (feedforward için)\n        shortcut = x\n        \n        # İkinci normalization işlemi: Feedforward ağına (MLP) geçiş öncesi\n        x = self.norm2(x)  # İkinci normalizasyon\n        x = self.ff(x)  # Feedforward (MLP) işlemi\n        \n        # Residual connection: feedforward çıktısı ile kısa yol bağlantısını topluyoruz\n        x = x + shortcut  # Kısa yol bağlantısı ekleniyor\n        \n        return x ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:49.516480Z","iopub.execute_input":"2025-03-19T12:49:49.516736Z","iopub.status.idle":"2025-03-19T12:49:49.534182Z","shell.execute_reply.started":"2025-03-19T12:49:49.516707Z","shell.execute_reply":"2025-03-19T12:49:49.533247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def text_to_token_ids(text, tokenizer):\n    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n    return encoded_tensor\n\ndef token_ids_to_text(token_ids, tokenizer):\n    flat = token_ids.squeeze(0)\n    return tokenizer.decode(flat.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:49.535051Z","iopub.execute_input":"2025-03-19T12:49:49.535282Z","iopub.status.idle":"2025-03-19T12:49:49.553915Z","shell.execute_reply.started":"2025-03-19T12:49:49.535259Z","shell.execute_reply":"2025-03-19T12:49:49.553058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GPTModel(nn.Module):\n\n    def __init__(self, cfg):\n        super().__init__()\n        # Token embedding tablosu: her token ID'si için d_model boyutunda vektörler.\n        # Vocab boyutu (cfg[\"vocab_size\"]) ve her token'in embedding boyutu (cfg[\"emb_dim\"]) parametreleriyle oluşturuluyor.\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n\n        # Positional embedding tablosu: her token'in cümledeki pozisyonunu temsil eden embedding.\n        # Cümledeki en uzun token sayısı (cfg[\"context_length\"]) ve embedding boyutu (cfg[\"emb_dim\"]) parametreleriyle oluşturuluyor.\n        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n\n        # Transformer bloklarının ardışık dizisi (Sequential): \n        # Burada modelin içinde cfg[\"n_layers\"] kadar TransformerBlock bulunuyor. \n        # Her TransformerBlock, attention ve feedforward katmanlarını içeriyor.\n        self.trf_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n        )\n\n        # Son layer normalization katmanı: Modelin çıktısı üzerinde normalizasyon uygulanarak, öğrenmenin stabilleşmesi sağlanır.\n        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n\n        # Çıktı başlığı (output head): Sonuçları vocab boyutuna (cfg[\"vocab_size\"]) eşleştiren bir lineer katman.\n        # Bu katman, modelin final tahminlerini yapabilmesi için gereklidir.\n        self.out_head = nn.Linear(\n            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n        )\n\n    def forward(self, in_idx):\n        # Girişin boyutlarını alıyoruz: (batch_size, seq_len)\n        batch_size, seq_len = in_idx.shape\n\n        # Token embeddingler: Her token ID'si için embeddingler alınıyor.\n        tok_embeds = self.tok_emb(in_idx)\n\n        # Positional embeddingler: Cümledeki her token'in pozisyonuna karşılık gelen embeddingler alınıyor.\n        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n\n        # Token ve positional embeddingleri topluyoruz. Bu şekilde hem token'in anlamı hem de pozisyonu dikkate alınır.\n        x = tok_embeds + pos_embeds\n\n        # Transformer bloklarında geçiyor: Modelin temel özelliklerini öğrenebilmesi için.\n        x = self.trf_blocks(x)\n\n        # Son layer normalization: Çıktıları normalize ediyoruz.\n        x = self.final_norm(x)\n\n        # Çıktıyı lineer katmandan geçiriyoruz. Bu, modelin vocab_size kadar olasılık dağılımı oluşturmasını sağlar.\n        logits = self.out_head(x)\n\n        # Sonuç olarak, logits (tahminler) döndürülüyor.\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:49.556455Z","iopub.execute_input":"2025-03-19T12:49:49.556690Z","iopub.status.idle":"2025-03-19T12:49:49.568176Z","shell.execute_reply.started":"2025-03-19T12:49:49.556671Z","shell.execute_reply":"2025-03-19T12:49:49.567416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = GPTModel(ModelConfig)\ndef generate_text_simple(model, idx,\n            max_new_tokens, context_size):\n    for i in range(max_new_tokens):\n        idx_cound = idx[:,-context_size:]\n        with torch.no_grad():\n            logits = model(idx_cound)\n\n        logits = logits[:,-1,:]\n        probas = torch.softmax(logits, dim=-1)\n        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n        idx = torch.cat((idx,idx_next), dim=1)\n\n    return idx\n\nstart_context = \"Merhaba ben\"\nencoded = tokenizer.encode(start_context)\nencoded_tensor = torch.tensor(encoded).unsqueeze(0)\nmodel.eval()\nout = generate_text_simple(\n model=model,\n idx=encoded_tensor,\n max_new_tokens=6,\n context_size=ModelConfig[\"context_length\"]\n)\n\ndecoded_text = tokenizer.decode(out.squeeze(0).tolist())\nprint(decoded_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:49.569648Z","iopub.execute_input":"2025-03-19T12:49:49.569881Z","iopub.status.idle":"2025-03-19T12:49:50.465392Z","shell.execute_reply.started":"2025-03-19T12:49:49.569862Z","shell.execute_reply":"2025-03-19T12:49:50.464515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file_path = \"/kaggle/input/tr-news/data.txt\"\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    text_data = f.read()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:49:50.466549Z","iopub.execute_input":"2025-03-19T12:49:50.466847Z","iopub.status.idle":"2025-03-19T12:50:02.133453Z","shell.execute_reply.started":"2025-03-19T12:49:50.466813Z","shell.execute_reply":"2025-03-19T12:50:02.132734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntotal_characters = len(text_data)\ntotal_tokens = len(tokenizer.encode(text_data))\nprint(\"Characters:\", total_characters)\nprint(\"Tokens:\", total_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:50:02.134183Z","iopub.execute_input":"2025-03-19T12:50:02.134423Z","iopub.status.idle":"2025-03-19T12:50:02.139643Z","shell.execute_reply.started":"2025-03-19T12:50:02.134404Z","shell.execute_reply":"2025-03-19T12:50:02.138940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ratio = .9\nsplit_idx = int(train_ratio * len(text_data))\ntrain_data = text_data[:split_idx]\nval_data = text_data[split_idx:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:50:02.140443Z","iopub.execute_input":"2025-03-19T12:50:02.140743Z","iopub.status.idle":"2025-03-19T12:50:03.927026Z","shell.execute_reply.started":"2025-03-19T12:50:02.140703Z","shell.execute_reply":"2025-03-19T12:50:03.926223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GPTDataset(Dataset):\n\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n\n        token_ids = tokenizer.encode(txt)\n       \n        for i in range(0, len(token_ids) - max_length, stride):\n            input_chunk = token_ids[i:i+max_length]\n            target_chunk = token_ids[i+1: i+1+max_length]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:50:03.927912Z","iopub.execute_input":"2025-03-19T12:50:03.928224Z","iopub.status.idle":"2025-03-19T12:50:03.943829Z","shell.execute_reply.started":"2025-03-19T12:50:03.928191Z","shell.execute_reply":"2025-03-19T12:50:03.943136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dataloader(text, batch_size, max_length,\n                     stride, shuffle, drop_last, num_workers):\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n    dataset = GPTDataset(text, tokenizer, max_length, stride)\n    dataloader = DataLoader(\n        dataset, \n        batch_size = batch_size,\n        shuffle = shuffle,\n        drop_last = drop_last,\n        num_workers = num_workers\n    )\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:50:03.944634Z","iopub.execute_input":"2025-03-19T12:50:03.944919Z","iopub.status.idle":"2025-03-19T12:50:03.973096Z","shell.execute_reply.started":"2025-03-19T12:50:03.944893Z","shell.execute_reply":"2025-03-19T12:50:03.972292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = create_dataloader(\n    train_data,\n    batch_size=32,\n    max_length=ModelConfig[\"context_length\"],\n    stride=ModelConfig[\"context_length\"],\n    drop_last=True,\n    shuffle=True,\n    num_workers=0\n)\n\nval_loader = create_dataloader(\n    val_data,\n    batch_size=32,\n    max_length=ModelConfig[\"context_length\"],\n    stride=ModelConfig[\"context_length\"],\n    drop_last=False,\n    shuffle=False,\n    num_workers=0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:50:03.973937Z","iopub.execute_input":"2025-03-19T12:50:03.974210Z","iopub.status.idle":"2025-03-19T12:53:22.037174Z","shell.execute_reply.started":"2025-03-19T12:50:03.974181Z","shell.execute_reply":"2025-03-19T12:53:22.036514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calc_loss_batch(input_batch, target_batch, model, device):\n    input_batch = input_batch.to(device)\n    target_batch = target_batch.to(device)\n    logits = model(input_batch)\n    loss = torch.nn.functional.cross_entropy(\n    logits.flatten(0, 1), target_batch.flatten()\n    )\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:53:22.037886Z","iopub.execute_input":"2025-03-19T12:53:22.038116Z","iopub.status.idle":"2025-03-19T12:53:22.042142Z","shell.execute_reply.started":"2025-03-19T12:53:22.038097Z","shell.execute_reply":"2025-03-19T12:53:22.041339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calc_loss_loader(data_loader, model, device, num_batches=None):\n    total_loss = 0.\n    if len(data_loader) == 0:\n        return float(\"nan\")\n    elif num_batches is None:\n        num_batches = len(data_loader)\n    else:\n        num_batches = min(num_batches, len(data_loader))\n\n    for i, (input_batch, target_batch) in enumerate(data_loader):\n        if i < num_batches:\n            loss = calc_loss_batch(\n            input_batch, target_batch, model, device\n            )\n            total_loss += loss.item()\n        else:\n            break\n    return total_loss / num_batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:53:22.043055Z","iopub.execute_input":"2025-03-19T12:53:22.043289Z","iopub.status.idle":"2025-03-19T12:53:22.060283Z","shell.execute_reply.started":"2025-03-19T12:53:22.043271Z","shell.execute_reply":"2025-03-19T12:53:22.059529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Eğer sistemde CUDA destekli bir GPU varsa \"cuda\" kullan, yoksa \"cpu\" kullan\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device) # modeli uygun olan cihaza taşı\nwith torch.no_grad():\n    train_loss = calc_loss_loader(train_loader, model, device)\n    val_loss = calc_loss_loader(val_loader, model, device)\n    \nprint(\"Training loss:\", train_loss)\nprint(\"Validation loss:\", val_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:53:22.061192Z","iopub.execute_input":"2025-03-19T12:53:22.061474Z","execution_failed":"2025-03-19T13:11:28.298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model_simple(model, train_loader, val_loader,\n                        optimizer, device, num_epochs,\n                        eval_freq, eval_iter, start_context, tokenizer):\n    train_losses, val_losses, track_tokens_seen = [], [], []\n    tokens_seen, global_step = 0, -1\n    for epoch in range(num_epochs):\n        model.train()\n        for input_batch, target_batch in train_loader:\n            optimizer.zero_grad()\n            loss = calc_loss_batch(\n                input_batch, target_batch, model, device\n            )\n            loss.backward()\n            optimizer.step()\n            tokens_seen += input_batch.numel()\n            global_step += 1\n\n            if global_step % eval_freq == 0:\n                train_loss, val_loss = evaluate_model(\n                    model, train_loader, val_loader, device, eval_iter)\n                train_losses.append(train_loss)\n                val_losses.append(val_loss)\n                track_tokens_seen.append(tokens_seen)\n                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n                    f\"Train loss {train_loss:.3f}, \"\n                    f\"Val loss {val_loss:.3f}\"\n                )\n        generate_and_print_sample(\n            model, tokenizer, device, start_context\n        )\n\n            # Epoch sonunda modeli kaydetme\n        checkpoint = {\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'global_step': global_step,\n            'tokens_seen': tokens_seen,\n            'train_losses': train_losses,\n            'val_losses': val_losses\n        }\n        torch.save(checkpoint, f'model_checkpoint_epoch_{epoch+1}.pth')\n        print(f\"Model kaydedildi: model_checkpoint_epoch_{epoch+1}.pth\")\n    return train_losses, val_losses, track_tokens_seen","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-19T13:11:28.298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n    model.eval()\n    with torch.no_grad():\n        train_loss = calc_loss_loader(\n            train_loader, model, device, num_batches=eval_iter\n         )\n        val_loss = calc_loss_loader(\n            val_loader, model, device, num_batches=eval_iter\n        )\n    model.train()\n    return train_loss, val_loss","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-19T13:11:28.298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_and_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    context_size = model.pos_emb.weight.shape[0]\n    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n    with torch.no_grad():\n        token_ids = generate_text_simple(\n            model=model, idx=encoded,\n            max_new_tokens=50, context_size=context_size\n        )\n    decoded_text = token_ids_to_text(token_ids, tokenizer)\n    print(decoded_text.replace(\"\\n\", \" \"))\n    model.train()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-19T13:11:28.298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(123)\nmodel = GPTModel(ModelConfig)\nmodel.to(device)\noptimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=0.0004, weight_decay=0.1\n)\nnum_epochs = 5\ntrain_losses, val_losses, tokens_seen = train_model_simple(\n    model, train_loader, val_loader, optimizer, device,\n    num_epochs=num_epochs, eval_freq=100, eval_iter=500,\n    start_context=\"Ben bir dil modeliyim\", tokenizer=tokenizer\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-19T13:11:28.298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\n\ndef plot_losses(epochs_seen, tokens_seen, train_losses, val_losses, file_name=None):\n    fig, ax1 = plt.subplots(figsize=(5, 3))\n    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n    ax1.plot(\n         epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n    )\n    ax1.set_xlabel(\"Epochs\")\n    ax1.set_ylabel(\"Loss\")\n    ax1.legend(loc=\"upper right\")\n    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n    ax2 = ax1.twiny()\n    ax2.plot(tokens_seen, train_losses, alpha=0)\n    ax2.set_xlabel(\"Tokens seen\")\n    fig.tight_layout()\n    \n    if file_name:\n        plt.savefig(file_name)  # Grafik dosyaya kaydedilir\n        print(f\"Grafik {file_name} olarak kaydedildi.\")\n    else:\n        plt.show()  \n\nepochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\nplot_losses(epochs_tensor, tokens_seen, train_losses, val_losses, file_name=\"training_loss_plot.png\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-19T13:11:28.298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}